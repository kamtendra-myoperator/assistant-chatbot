{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.5)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.19)\n",
      "Requirement already satisfied: langchain-experimental in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.50)\n",
      "Requirement already satisfied: InstructorEmbedding in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: openai in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.12.0)\n",
      "Collecting tiktoken==0.4.0\n",
      "  Downloading tiktoken-0.4.0-cp310-cp310-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: faiss-cpu==1.7.4 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.19.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken==0.4.0) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken==0.4.0) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.22 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.1.22)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\kamte\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (8.2.3)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.0.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested tiktoken==0.4.0\n",
      "    langchain-openai 0.0.5 depends on tiktoken<0.6.0 and >=0.5.2\n",
      "    The user requested tiktoken==0.4.0\n",
      "    langchain-openai 0.0.6 depends on tiktoken<1 and >=0.5.2\n",
      "    The user requested tiktoken==0.4.0\n",
      "    langchain-openai 0.0.4 depends on tiktoken<0.6.0 and >=0.5.2\n",
      "    The user requested tiktoken==0.4.0\n",
      "    langchain-openai 0.0.3 depends on tiktoken<0.6.0 and >=0.5.2\n",
      "    The user requested tiktoken==0.4.0\n",
      "    langchain-openai 0.0.2.post1 depends on tiktoken<0.6.0 and >=0.5.2\n",
      "    The user requested tiktoken==0.4.0\n",
      "    langchain-openai 0.0.2 depends on tiktoken<0.6.0 and >=0.5.2\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install langchain-openai==0.0.2, langchain-openai==0.0.2.post1, langchain-openai==0.0.3, langchain-openai==0.0.4, langchain-openai==0.0.5, langchain-openai==0.0.6 and tiktoken==0.4.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "# Installing Dependencies\n",
    "%pip install langchain langchain-openai google-generativeai sentence-transformers langchain_community langchain-community langchain-experimental InstructorEmbedding python-dotenv==1.0.0 openai tiktoken==0.4.0 faiss-cpu==1.7.4 protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x000001FC290838E0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001FC290AD120>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open-AI LLM\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEYS=os.getenv('OPENAI_API_KEYS')\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEYS)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nMy name is OpenAI, a powerful AI designed to assist and interact with users. How can I help you?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Time Slots: Eash Hoskote\\n8:00:00: Available\\n8:15:00: Booked\\n8:30:00: Available\\n8:45:00: Available\\n9:00:00: Booked\\n9:15:00: Not Available\\n9:30:00: Booked\\n9:45:00: Not Available\\n10:00:00: Not Available\\n10:15:00: Not Available\\n10:30:00: Not Available\\n10:45:00: Available\\n11:00:00: Not Available\\n11:15:00: Available\\n11:30:00: Not Available\\n11:45:00: Booked\\n12:00:00: Not Available\\n12:15:00: Not Available\\n12:30:00: Not Available\\n12:45:00: Booked\\n13:00:00: Booked\\n13:15:00: Available\\n13:30:00: Booked\\n13:45:00: Not Available\\n14:00:00: Available\\n14:15:00: Available\\n14:30:00: Booked\\n14:45:00: Not Available\\n15:00:00: Not Available\\n15:15:00: Booked\\n15:30:00: Booked\\n15:45:00: Not Available\\n16:00:00: Not Available\\n16:15:00: Booked\\n16:30:00: Available\\n16:45:00: Not Available\\n17:00:00: Not Available\\n17:15:00: Not Available\\n17:30:00: Not Available\\n17:45:00: Not Available\\n18:00:00: Available\\n18:15:00: Booked\\n18:30:00: Not Available\\n18:45:00: Available\\n19:00:00: Booked\\n19:15:00: Available\\n19:30:00: Not Available\\n19:45:00: Not Available\\n20:00:00: Not Available\\n20:15:00: Booked\\n20:30:00: Available\\n20:45:00: Available\\n21:00:00: Available\\n21:15:00: Available\\n21:30:00: Booked\\n21:45:00: Not Available\\nAvailable: Available', metadata={'source': 'Transformed-Slots.csv', 'row': 0}),\n",
       " Document(page_content='Time Slots: Sarbari Gupta\\n8:00:00: Available\\n8:15:00: Not Available\\n8:30:00: Booked\\n8:45:00: Booked\\n9:00:00: Available\\n9:15:00: Not Available\\n9:30:00: Not Available\\n9:45:00: Booked\\n10:00:00: Booked\\n10:15:00: Available\\n10:30:00: Booked\\n10:45:00: Not Available\\n11:00:00: Available\\n11:15:00: Available\\n11:30:00: Booked\\n11:45:00: Booked\\n12:00:00: Booked\\n12:15:00: Booked\\n12:30:00: Booked\\n12:45:00: Available\\n13:00:00: Available\\n13:15:00: Not Available\\n13:30:00: Available\\n13:45:00: Booked\\n14:00:00: Not Available\\n14:15:00: Booked\\n14:30:00: Booked\\n14:45:00: Available\\n15:00:00: Not Available\\n15:15:00: Available\\n15:30:00: Not Available\\n15:45:00: Not Available\\n16:00:00: Booked\\n16:15:00: Available\\n16:30:00: Booked\\n16:45:00: Available\\n17:00:00: Not Available\\n17:15:00: Available\\n17:30:00: Available\\n17:45:00: Not Available\\n18:00:00: Available\\n18:15:00: Available\\n18:30:00: Not Available\\n18:45:00: Booked\\n19:00:00: Not Available\\n19:15:00: Not Available\\n19:30:00: Booked\\n19:45:00: Booked\\n20:00:00: Available\\n20:15:00: Not Available\\n20:30:00: Booked\\n20:45:00: Available\\n21:00:00: Not Available\\n21:15:00: Available\\n21:30:00: Not Available\\n21:45:00: Booked\\nAvailable: Available', metadata={'source': 'Transformed-Slots.csv', 'row': 1}),\n",
       " Document(page_content='Time Slots: Dr. LakshmiKant N\\n8:00:00: Available\\n8:15:00: Available\\n8:30:00: Not Available\\n8:45:00: Not Available\\n9:00:00: Booked\\n9:15:00: Available\\n9:30:00: Not Available\\n9:45:00: Available\\n10:00:00: Not Available\\n10:15:00: Available\\n10:30:00: Not Available\\n10:45:00: Available\\n11:00:00: Booked\\n11:15:00: Booked\\n11:30:00: Available\\n11:45:00: Available\\n12:00:00: Booked\\n12:15:00: Booked\\n12:30:00: Booked\\n12:45:00: Booked\\n13:00:00: Not Available\\n13:15:00: Available\\n13:30:00: Not Available\\n13:45:00: Booked\\n14:00:00: Not Available\\n14:15:00: Not Available\\n14:30:00: Not Available\\n14:45:00: Available\\n15:00:00: Booked\\n15:15:00: Available\\n15:30:00: Available\\n15:45:00: Not Available\\n16:00:00: Not Available\\n16:15:00: Booked\\n16:30:00: Booked\\n16:45:00: Booked\\n17:00:00: Not Available\\n17:15:00: Booked\\n17:30:00: Available\\n17:45:00: Not Available\\n18:00:00: Not Available\\n18:15:00: Not Available\\n18:30:00: Not Available\\n18:45:00: Available\\n19:00:00: Available\\n19:15:00: Available\\n19:30:00: Available\\n19:45:00: Not Available\\n20:00:00: Available\\n20:15:00: Booked\\n20:30:00: Not Available\\n20:45:00: Available\\n21:00:00: Not Available\\n21:15:00: Booked\\n21:30:00: Not Available\\n21:45:00: Booked\\nAvailable: Available', metadata={'source': 'Transformed-Slots.csv', 'row': 2}),\n",
       " Document(page_content='Time Slots: Dr. KVS Mahesh\\n8:00:00: Not Available\\n8:15:00: Not Available\\n8:30:00: Available\\n8:45:00: Available\\n9:00:00: Not Available\\n9:15:00: Booked\\n9:30:00: Not Available\\n9:45:00: Not Available\\n10:00:00: Not Available\\n10:15:00: Booked\\n10:30:00: Not Available\\n10:45:00: Not Available\\n11:00:00: Booked\\n11:15:00: Booked\\n11:30:00: Not Available\\n11:45:00: Available\\n12:00:00: Booked\\n12:15:00: Booked\\n12:30:00: Not Available\\n12:45:00: Not Available\\n13:00:00: Available\\n13:15:00: Not Available\\n13:30:00: Booked\\n13:45:00: Available\\n14:00:00: Available\\n14:15:00: Booked\\n14:30:00: Booked\\n14:45:00: Not Available\\n15:00:00: Booked\\n15:15:00: Available\\n15:30:00: Not Available\\n15:45:00: Available\\n16:00:00: Not Available\\n16:15:00: Booked\\n16:30:00: Not Available\\n16:45:00: Booked\\n17:00:00: Available\\n17:15:00: Not Available\\n17:30:00: Booked\\n17:45:00: Booked\\n18:00:00: Available\\n18:15:00: Not Available\\n18:30:00: Available\\n18:45:00: Available\\n19:00:00: Booked\\n19:15:00: Not Available\\n19:30:00: Booked\\n19:45:00: Not Available\\n20:00:00: Not Available\\n20:15:00: Available\\n20:30:00: Booked\\n20:45:00: Booked\\n21:00:00: Booked\\n21:15:00: Booked\\n21:30:00: Booked\\n21:45:00: Not Available\\nAvailable: Available', metadata={'source': 'Transformed-Slots.csv', 'row': 3})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Company's data as CSV\n",
    "# Note: It can be loaded and updated in any format according to need\n",
    "\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path=\"Transformed-Slots.csv\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "jq package not found, please install it with `pip install jq`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kamte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\document_loaders\\json_loader.py:45\u001b[0m, in \u001b[0;36mJSONLoader.__init__\u001b[1;34m(self, file_path, jq_schema, content_key, metadata_func, text_content, json_lines)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjq\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jq'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONLoader\n\u001b[1;32m----> 3\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mJSONLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./example_data/facebook_chat.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjq_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.doctors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[1;32mc:\\Users\\kamte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\document_loaders\\json_loader.py:47\u001b[0m, in \u001b[0;36mJSONLoader.__init__\u001b[1;34m(self, file_path, jq_schema, content_key, metadata_func, text_content, json_lines)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjq\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjq package not found, please install it with `pip install jq`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m     )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m Path(file_path)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jq_schema \u001b[38;5;241m=\u001b[39m jq\u001b[38;5;241m.\u001b[39mcompile(jq_schema)\n",
      "\u001b[1;31mImportError\u001b[0m: jq package not found, please install it with `pip install jq`"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path='./slots.json',\n",
    "    jq_schema='.doctors',\n",
    "    text_content=False)\n",
    "\n",
    "data = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# Creating Embedding using Langchain's InstructEmbeddings\n",
    "# Doc: https://python.langchain.com/docs/integrations/text_embedding/instruct_embeddings\n",
    "# Note: Most voted embedding on LangChain leaderboard should be used\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Embedding in Vector Database (FAISS) \n",
    "# Vectorisation\n",
    "# Note: Chroma Vector Database should be efficient\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vector_db = FAISS.from_documents(documents=data, embedding=instructor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading vector database\n",
    "\n",
    "vector_db.save_local(\"./transformed-slots_vector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"./slots_vector\", instructor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever\n",
    "\n",
    "retriever1 = new_db.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Conversational chain with memory, retriever and LLM\n",
    "# Note: Different methods to pass chat-history in the main prompt are demonstrated here: \n",
    "# https://colab.research.google.com/drive/1q3K5Rq_l58p9cHmP-yIApCnYE-eAtzDG?usp=sharing#scrollTo=X6_ptbbCvReJ\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory, ConversationKGMemory, ConversationSummaryBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context, question and chat_history, generate an answer based on this context and chat history.\n",
    "    In the source document, there are rows indicating different Doctors and columns indicating time slots in 24 Hour Format. /n\n",
    "    If in that particular time slot have 'Available' value, it means that doctor is available in that time slot. /n\n",
    "    If in that particular time slot have 'Booked' value, it means that doctor is not available in that time slot. /n\n",
    "    And if in that particular time slot have 'Not Available' value, it means that doctor is not available in that time slot. /n\n",
    "    If you do not get valid answer, do not make up my your own and return 'i dont know'.\n",
    "    /n\n",
    "    CONTEXT: {context}\n",
    "    /n\n",
    "    CHAT_HISTORY: {chat_history}\n",
    "    /n\n",
    "    QUESTION: {question}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\", \"chat_history\", \"question\"]\n",
    "        )\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "        llm=llm,\n",
    "        memory_key='chat_history', input_key=\"question\", output_key=\"answer\")\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        chain_type = \"stuff\",\n",
    "        verbose=True,\n",
    "        retriever=retriever1,\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "        get_chat_history=lambda h : h,\n",
    "        combine_docs_chain_kwargs={'prompt': prompt},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following context, question and chat_history, generate an answer based on this context and chat history.\n",
      "    In the source document, there are rows indicating different Doctors and columns indicating time slots in 24 Hour Format. /n\n",
      "    If in that particular time slot have 'Available' value, it means that doctor is available in that time slot. /n\n",
      "    If in that particular time slot have 'Booked' value, it means that doctor is not available in that time slot. /n\n",
      "    And if in that particular time slot have 'Not Available' value, it means that doctor is not available in that time slot. /n\n",
      "    If you do not get valid answer, do not make up my your own and return 'i dont know'.\n",
      "    /n\n",
      "    CONTEXT: : \n",
      "Eash Hoskote: Available\n",
      "Sarbari Gupta: Available\n",
      "Dr. LakshmiKant N: Available\n",
      "Dr. KVS Mahesh: NA\n",
      "1: 2\n",
      "Available: Booked\n",
      "\n",
      ": \n",
      "Eash Hoskote: Available\n",
      "Sarbari Gupta: Booked\n",
      "Dr. LakshmiKant N: Available\n",
      "Dr. KVS Mahesh: Available\n",
      "1: \n",
      "Available: \n",
      "\n",
      ": \n",
      "Eash Hoskote: Available\n",
      "Sarbari Gupta: Available\n",
      "Dr. LakshmiKant N: NA\n",
      "Dr. KVS Mahesh: Available\n",
      "1: \n",
      "Available: \n",
      "    /n\n",
      "    CHAT_HISTORY: \n",
      "    /n\n",
      "    QUESTION: what doctors available at 8am\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'what doctors available at 8am',\n",
       " 'chat_history': '',\n",
       " 'answer': '\\n\\n\\nThe only doctor that is available at 8am is Dr. KVS Mahesh.',\n",
       " 'source_documents': [Document(page_content=': \\nEash Hoskote: Available\\nSarbari Gupta: Available\\nDr. LakshmiKant N: Available\\nDr. KVS Mahesh: NA\\n1: 2\\nAvailable: Booked', metadata={'source': 'slots.csv', 'row': 0}),\n",
       "  Document(page_content=': \\nEash Hoskote: Available\\nSarbari Gupta: Booked\\nDr. LakshmiKant N: Available\\nDr. KVS Mahesh: Available\\n1: \\nAvailable: ', metadata={'source': 'slots.csv', 'row': 43}),\n",
       "  Document(page_content=': \\nEash Hoskote: Available\\nSarbari Gupta: Available\\nDr. LakshmiKant N: NA\\nDr. KVS Mahesh: Available\\n1: \\nAvailable: ', metadata={'source': 'slots.csv', 'row': 40})]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"what doctors available at 8am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "df = pd.read_csv(\"slots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key = os.getenv('OPENAI_API_KEYS'), temperature=0, model=\"gpt-3.5-turbo-0613\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(\n",
    "    model,\n",
    "    df,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \n",
    "         \"\"\"\n",
    "          You are a helpful AI assistant expert in quering from csv to find answers. Return answer in descriptive form not in form of array of data or something.\n",
    "          /n\n",
    "          In the source document, there are rows indicating different Doctors and columns indicating time slots. /n\n",
    "            If in that particular time slot have 'Available' value, it means that doctor is available in that time slot. /n\n",
    "            If in that particular time slot have 'Booked' value, it means that doctor is not available in that time slot. /n\n",
    "            And if in that particular time slot have 'NA' value, it means that doctor is not available in that time slot. /n\n",
    "            If you do not get valid answer, do not make up my your own and return 'i dont know'.\n",
    "         \"\"\"\n",
    "         ),\n",
    "        (\"user\", \"{question}\\n ai: \"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['8:00 AM'] == 'Available'].columns.tolist()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mKeyError: '8:00 AM'\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'df.columns.tolist()'}`\n",
      "responded: It seems that there is an error because the column name '8:00 AM' does not exist in the dataframe. Let me check the column names to see if there is a similar column.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Unnamed: 0', 'Eash Hoskote', 'Sarbari Gupta', 'Dr. LakshmiKant N', 'Dr. KVS Mahesh', 'Unnamed: 5', 'Unnamed: 6', '1', 'Available', 'Unnamed: 9']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['Unnamed: 0'] == '8:00 AM']['Available'].tolist()\"}`\n",
      "responded: The available column names in the dataframe are: 'Unnamed: 0', 'Eash Hoskote', 'Sarbari Gupta', 'Dr. LakshmiKant N', 'Dr. KVS Mahesh', 'Unnamed: 5', 'Unnamed: 6', '1', 'Available', and 'Unnamed: 9'. \n",
      "\n",
      "Let me check which doctors are 'Available' at 8am using the 'Available' column.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Booked']\u001b[0m\u001b[32;1m\u001b[1;3mAccording to the dataframe, the doctor who is 'Available' at 8am is 'Booked'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"According to the dataframe, the doctor who is 'Available' at 8am is 'Booked'.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent.run(\n",
    "        \"What doctors are 'Available' at 8am\"\n",
    "  )\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['8:00 AM'] == 'Available'].columns.tolist()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mKeyError: '8:00 AM'\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'df.columns.tolist()'}`\n",
      "responded: It seems that there is an error because the column name '8:00 AM' does not exist in the dataframe. Let me check the column names to see if there is a similar column.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Unnamed: 0', 'Eash Hoskote', 'Sarbari Gupta', 'Dr. LakshmiKant N', 'Dr. KVS Mahesh', 'Unnamed: 5', 'Unnamed: 6', '1', 'Available', 'Unnamed: 9']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['Available'] == 'Available'].columns.tolist()\"}`\n",
      "responded: The available column names in the dataframe are: 'Unnamed: 0', 'Eash Hoskote', 'Sarbari Gupta', 'Dr. LakshmiKant N', 'Dr. KVS Mahesh', 'Unnamed: 5', 'Unnamed: 6', '1', 'Available', and 'Unnamed: 9'. \n",
      "\n",
      "Let me check which doctors are 'Available' at 8am using the 'Available' column.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Unnamed: 0', 'Eash Hoskote', 'Sarbari Gupta', 'Dr. LakshmiKant N', 'Dr. KVS Mahesh', 'Unnamed: 5', 'Unnamed: 6', '1', 'Available', 'Unnamed: 9']\u001b[0m\u001b[32;1m\u001b[1;3mBased on the available column names, it seems that all doctors are 'Available' at 8am.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What doctors are 'Available' at 8am\",\n",
       " 'output': \"Based on the available column names, it seems that all doctors are 'Available' at 8am.\"}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt.format(\n",
    "        question=\"what is the deatils of the product purchased by 'John Doe'\"\n",
    "  )\n",
    "\n",
    "agent(\"What doctors are 'Available' at 8am\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
